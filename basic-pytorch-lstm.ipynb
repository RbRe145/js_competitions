{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Basic LSTM with a single sequence\n"]},{"cell_type":"markdown","metadata":{},"source":["I've prepared a very basic training loop in torch using an LSTM, this notebook only uses one sequence and doesn't use the available lags. So far my experimentations have resulted in worse overfitting when using additional time steps. The basic LSTM overfits quite intensely as well. I'd love some suggestions on how to fix this."]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-09T16:12:35.364585Z","iopub.status.busy":"2024-11-09T16:12:35.364169Z","iopub.status.idle":"2024-11-09T16:12:36.377140Z","shell.execute_reply":"2024-11-09T16:12:36.376203Z","shell.execute_reply.started":"2024-11-09T16:12:35.364545Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:36.380057Z","iopub.status.busy":"2024-11-09T16:12:36.379247Z","iopub.status.idle":"2024-11-09T16:12:40.977383Z","shell.execute_reply":"2024-11-09T16:12:40.976309Z","shell.execute_reply.started":"2024-11-09T16:12:36.380007Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","import torch.nn as nn\n","\n","import torch.nn.functional as F\n","\n","import pandas as pd\n","\n","\n","\n","import numpy as np\n","\n","import statistics as stat\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.metrics import roc_auc_score\n","\n","import copy\n","\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch.optim as optim\n","\n","import copy\n","\n","import polars as pl\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:40.979257Z","iopub.status.busy":"2024-11-09T16:12:40.978679Z","iopub.status.idle":"2024-11-09T16:12:40.983539Z","shell.execute_reply":"2024-11-09T16:12:40.982610Z","shell.execute_reply.started":"2024-11-09T16:12:40.979210Z"},"trusted":true},"outputs":[],"source":["jane_street_real_time_market_data_forecasting_path = '/root/js_competitions/data'"]},{"cell_type":"markdown","metadata":{},"source":["## Basic Model architecture"]},{"cell_type":"markdown","metadata":{},"source":["### Gaussian Nose\n","I added some gaussian noise to the model to attempt to reduce overfitting, it hepls a bit but not perfectly."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:40.986144Z","iopub.status.busy":"2024-11-09T16:12:40.985851Z","iopub.status.idle":"2024-11-09T16:12:40.994775Z","shell.execute_reply":"2024-11-09T16:12:40.993999Z","shell.execute_reply.started":"2024-11-09T16:12:40.986113Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class GaussianNoise(nn.Module):\n","    def __init__(self, std=0.1):\n","        super().__init__()\n","        self.std = std\n","\n","    def forward(self, x):\n","        if self.training:  # Only add noise during training\n","            noise = torch.randn_like(x) * self.std\n","            return x + noise\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["### Basic LSTM"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:40.996619Z","iopub.status.busy":"2024-11-09T16:12:40.996159Z","iopub.status.idle":"2024-11-09T16:12:41.005994Z","shell.execute_reply":"2024-11-09T16:12:41.005158Z","shell.execute_reply.started":"2024-11-09T16:12:40.996577Z"},"trusted":true},"outputs":[],"source":["class LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_dim, output_size, num_layers):\n","        super(LSTM, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.noise = GaussianNoise(std = .1)\n","        self.lstm = nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_size)\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","        x = self.noise(x)\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","        return out.squeeze()"]},{"cell_type":"markdown","metadata":{},"source":["## Training Data Normalization"]},{"cell_type":"markdown","metadata":{},"source":["I've found this to be quite necessary for the data, I've collected the means and standard deviations for all of the feature columns in the data and placed them in dicts here. It's what allows this model to have a postive R^2 but it also increases the overfitting. "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:41.007471Z","iopub.status.busy":"2024-11-09T16:12:41.007171Z","iopub.status.idle":"2024-11-09T16:12:41.033727Z","shell.execute_reply":"2024-11-09T16:12:41.032783Z","shell.execute_reply.started":"2024-11-09T16:12:41.007440Z"},"trusted":true},"outputs":[],"source":["means = {'feature_00': 0.640198826789856, 'feature_01': 0.03755598142743111, 'feature_02': 0.6368075609207153, 'feature_03': 0.6365063786506653, 'feature_04': 0.013741530478000641, 'feature_05': -0.02173694409430027, 'feature_06': -0.006415014620870352, 'feature_07': -0.010971736162900925, 'feature_08': -0.04653771221637726, 'feature_09': 32.596106194690265, 'feature_10': 4.95929203539823, 'feature_11': 167.6541592920354, 'feature_12': -0.13415881991386414, 'feature_13': -0.07573335617780685, 'feature_14': -0.12015637010335922, 'feature_15': -0.7470195889472961, 'feature_16': -0.6257441639900208, 'feature_17': -0.7294047474861145, 'feature_18': -0.042215555906295776, 'feature_19': -0.08798160403966904, 'feature_20': -0.15741558372974396, 'feature_21': 0.10528526455163956, 'feature_22': 0.018054703250527382, 'feature_23': 0.03165541961789131, 'feature_24': 2.733017921447754, 'feature_25': 0.39958420395851135, 'feature_26': -0.11045943945646286, 'feature_27': -0.5332594513893127, 'feature_28': -0.4522790312767029, 'feature_29': -0.5739678144454956, 'feature_30': -0.7905704975128174, 'feature_31': 0.10600688308477402, 'feature_32': 0.40044134855270386, 'feature_33': -0.021725023165345192, 'feature_34': 0.4226262867450714, 'feature_35': 0.42143046855926514, 'feature_36': -0.00023802756913937628, 'feature_37': 0.027961043640971184, 'feature_38': 0.010258913040161133, 'feature_39': 0.005768273025751114, 'feature_40': 0.017485467717051506, 'feature_41': 0.038347117602825165, 'feature_42': -0.06123563274741173, 'feature_43': -0.11644423753023148, 'feature_44': -0.12342483550310135, 'feature_45': -0.028769943863153458, 'feature_46': -0.015200662426650524, 'feature_47': 0.015717582777142525, 'feature_48': -0.0033910537604242563, 'feature_49': -0.0052393232472240925, 'feature_50': -0.2285808026790619, 'feature_51': -0.3548349440097809, 'feature_52': -0.358092725276947, 'feature_53': 0.2607136368751526, 'feature_54': 0.18796788156032562, 'feature_55': 0.3154229521751404, 'feature_56': -0.1471923440694809, 'feature_57': 0.15730056166648865, 'feature_58': -0.021774644032120705, 'feature_59': -0.0037768862675875425, 'feature_60': -0.010220836848020554, 'feature_61': -0.03178725391626358, 'feature_62': -0.3769100308418274, 'feature_63': -0.3229374587535858, 'feature_64': -0.3718394339084625, 'feature_65': -0.10233989357948303, 'feature_66': -0.13688170909881592, 'feature_67': -0.14402112364768982, 'feature_68': -0.06875362992286682, 'feature_69': -0.11862917989492416, 'feature_70': -0.11789549142122269, 'feature_71': -0.06013699993491173, 'feature_72': -0.10766122490167618, 'feature_73': -0.09921672940254211, 'feature_74': -0.10233042389154434, 'feature_75': -0.05991339311003685, 'feature_76': -0.06349952518939972, 'feature_77': -0.07424316555261612, 'feature_78': -0.07759837061166763}\n","stds = {'feature_00': 1.027751088142395, 'feature_01': 1.0967519283294678, 'feature_02': 1.0156300067901611, 'feature_03': 1.0170334577560425, 'feature_04': 1.0726385116577148, 'feature_05': 0.9639211297035217, 'feature_06': 1.0963259935379028, 'feature_07': 1.0789952278137207, 'feature_08': 0.7962697148323059, 'feature_09': 23.72976726545254, 'feature_10': 3.1867162933797224, 'feature_11': 163.44513161352285, 'feature_12': 0.6700984835624695, 'feature_13': 0.5805172920227051, 'feature_14': 0.664044201374054, 'feature_15': 0.37517768144607544, 'feature_16': 0.3393096327781677, 'feature_17': 0.3603287935256958, 'feature_18': 0.9911752939224243, 'feature_19': 1.0550744533538818, 'feature_20': 0.6643751263618469, 'feature_21': 0.38239365816116333, 'feature_22': 0.950261116027832, 'feature_23': 0.8119344711303711, 'feature_24': 1.4362775087356567, 'feature_25': 1.0947270393371582, 'feature_26': 1.077124834060669, 'feature_27': 1.0645726919174194, 'feature_28': 1.0676648616790771, 'feature_29': 0.2640742361545563, 'feature_30': 0.19689509272575378, 'feature_31': 0.3815343976020813, 'feature_32': 1.2996565103530884, 'feature_33': 0.9989405870437622, 'feature_34': 1.3409572839736938, 'feature_35': 1.3365675210952759, 'feature_36': 0.8695492148399353, 'feature_37': 0.7334080934524536, 'feature_38': 0.698810338973999, 'feature_39': 0.7965824604034424, 'feature_40': 0.518515944480896, 'feature_41': 0.6384949088096619, 'feature_42': 0.8168442249298096, 'feature_43': 0.5228385925292969, 'feature_44': 0.6521403193473816, 'feature_45': 0.8666537404060364, 'feature_46': 0.9039222002029419, 'feature_47': 3.2711963653564453, 'feature_48': 0.6570901274681091, 'feature_49': 0.7083076238632202, 'feature_50': 1.0132617950439453, 'feature_51': 0.6081287860870361, 'feature_52': 0.9250587224960327, 'feature_53': 1.0421689748764038, 'feature_54': 0.5859629511833191, 'feature_55': 0.9191848039627075, 'feature_56': 0.9549097418785095, 'feature_57': 1.0204777717590332, 'feature_58': 0.8327276110649109, 'feature_59': 0.8309783339500427, 'feature_60': 0.8389413356781006, 'feature_61': 1.192766547203064, 'feature_62': 1.388945460319519, 'feature_63': 0.09957146644592285, 'feature_64': 0.3396177291870117, 'feature_65': 1.01683509349823, 'feature_66': 1.0824761390686035, 'feature_67': 0.642227828502655, 'feature_68': 0.5312599539756775, 'feature_69': 0.6208390593528748, 'feature_70': 0.6724499464035034, 'feature_71': 0.5356909036636353, 'feature_72': 0.6534596681594849, 'feature_73': 1.0855497121810913, 'feature_74': 1.0880277156829834, 'feature_75': 1.2321789264678955, 'feature_76': 1.2345560789108276, 'feature_77': 1.0921478271484375, 'feature_78': 1.0924347639083862}\n","def normalize_dataframe(df: pl.DataFrame, means: dict, stds: dict) -> pl.DataFrame:\n","    \"\"\"\n","    Normalize a Polars DataFrame using the provided means and standard deviations.\n","\n","    Args:\n","    df (pl.DataFrame): The input DataFrame to normalize\n","    means (dict): A dictionary of column means\n","    stds (dict): A dictionary of column standard deviations\n","\n","    Returns:\n","    pl.DataFrame: The normalized DataFrame\n","    \"\"\"\n","\n","    # Create a list to store our normalization expressions\n","    normalize_exprs = []\n","\n","    for col in df.columns:\n","        if col in means and col in stds:\n","            # Ensure we don't divide by zero\n","            if stds[col] != 0:\n","                normalize_exprs.append(\n","                    ((pl.col(col) - means[col]) / stds[col]).alias(col)\n","                )\n","            else:\n","                # If std is 0, just subtract the mean\n","                normalize_exprs.append(\n","                    (pl.col(col) - means[col]).alias(col)\n","                )\n","        else:\n","            # If we don't have mean/std for this column, leave it as is\n","            normalize_exprs.append(pl.col(col))\n","\n","    # Apply the normalization to the dataframe\n","    normalized_df = df.select(normalize_exprs)\n","\n","    return normalized_df"]},{"cell_type":"markdown","metadata":{},"source":["# Preparing the Training Data"]},{"cell_type":"markdown","metadata":{},"source":["Date to to start the training data from, data collection gotten from https://www.kaggle.com/code/chumajin/janestreet-updated-simulator-for-time-series-api"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:41.035123Z","iopub.status.busy":"2024-11-09T16:12:41.034842Z","iopub.status.idle":"2024-11-09T16:12:41.045746Z","shell.execute_reply":"2024-11-09T16:12:41.044826Z","shell.execute_reply.started":"2024-11-09T16:12:41.035092Z"},"trusted":true},"outputs":[],"source":["valid_from = 1455 # for private you should change to 1455 (1 year)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:41.047170Z","iopub.status.busy":"2024-11-09T16:12:41.046878Z","iopub.status.idle":"2024-11-09T16:12:49.759414Z","shell.execute_reply":"2024-11-09T16:12:49.758570Z","shell.execute_reply.started":"2024-11-09T16:12:41.047139Z"},"trusted":true},"outputs":[],"source":["alltraindata = pl.scan_parquet(f\"{jane_street_real_time_market_data_forecasting_path}/train.parquet\")\n","train = alltraindata.filter(pl.col(\"date_id\")>=valid_from).collect()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:49.761015Z","iopub.status.busy":"2024-11-09T16:12:49.760640Z","iopub.status.idle":"2024-11-09T16:12:49.766040Z","shell.execute_reply":"2024-11-09T16:12:49.765120Z","shell.execute_reply.started":"2024-11-09T16:12:49.760976Z"},"trusted":true},"outputs":[],"source":["feature_names = [f\"feature_{i:02d}\" for i in range(79)]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:49.770360Z","iopub.status.busy":"2024-11-09T16:12:49.769922Z","iopub.status.idle":"2024-11-09T16:12:49.781488Z","shell.execute_reply":"2024-11-09T16:12:49.780426Z","shell.execute_reply.started":"2024-11-09T16:12:49.770324Z"},"trusted":true},"outputs":[],"source":["train_features = train.select(feature_names)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:49.784000Z","iopub.status.busy":"2024-11-09T16:12:49.782988Z","iopub.status.idle":"2024-11-09T16:12:52.039195Z","shell.execute_reply":"2024-11-09T16:12:52.038129Z","shell.execute_reply.started":"2024-11-09T16:12:49.783960Z"},"trusted":true},"outputs":[],"source":["train_features = train_features.fill_null(strategy='forward').fill_null(0)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:52.041399Z","iopub.status.busy":"2024-11-09T16:12:52.040458Z","iopub.status.idle":"2024-11-09T16:12:53.798008Z","shell.execute_reply":"2024-11-09T16:12:53.796949Z","shell.execute_reply.started":"2024-11-09T16:12:52.041363Z"},"trusted":true},"outputs":[],"source":["train_features = normalize_dataframe(train_features,means,stds)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:53.799785Z","iopub.status.busy":"2024-11-09T16:12:53.799377Z","iopub.status.idle":"2024-11-09T16:12:57.047411Z","shell.execute_reply":"2024-11-09T16:12:57.046249Z","shell.execute_reply.started":"2024-11-09T16:12:53.799739Z"},"trusted":true},"outputs":[],"source":["X  = train_features.to_numpy()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:57.049053Z","iopub.status.busy":"2024-11-09T16:12:57.048560Z","iopub.status.idle":"2024-11-09T16:12:57.088489Z","shell.execute_reply":"2024-11-09T16:12:57.087526Z","shell.execute_reply.started":"2024-11-09T16:12:57.049018Z"},"trusted":true},"outputs":[],"source":["y = train.select('responder_6').to_numpy().reshape(-1)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:57.090153Z","iopub.status.busy":"2024-11-09T16:12:57.089837Z","iopub.status.idle":"2024-11-09T16:12:57.128440Z","shell.execute_reply":"2024-11-09T16:12:57.127259Z","shell.execute_reply.started":"2024-11-09T16:12:57.090119Z"},"trusted":true},"outputs":[],"source":["weights = train.select('weight').to_numpy().reshape(-1)"]},{"cell_type":"markdown","metadata":{},"source":["## Train Validation Test Split"]},{"cell_type":"markdown","metadata":{},"source":["Using 80% of the data for training 10% for Validation and early stopping, 10% for final Testing"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:57.133354Z","iopub.status.busy":"2024-11-09T16:12:57.132934Z","iopub.status.idle":"2024-11-09T16:12:57.143683Z","shell.execute_reply":"2024-11-09T16:12:57.142687Z","shell.execute_reply.started":"2024-11-09T16:12:57.133309Z"},"trusted":true},"outputs":[],"source":["n_test = int(len(X) * .2)\n","train_X,t_X = X[:-n_test], X[-n_test:]\n","train_y ,t_y = y[:-n_test], y[-n_test:]\n","train_weights, t_weights = weights[:-n_test], weights[-n_test:]\n","val_n = int(len(t_y) * .5)\n","val_X,test_X = t_X[:-val_n], t_X[-val_n:]\n","val_y, test_y = t_y[:-val_n], t_y[-val_n:]\n","val_weights, test_weights = t_weights[:-val_n], t_weights[-val_n:]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:57.145367Z","iopub.status.busy":"2024-11-09T16:12:57.144951Z","iopub.status.idle":"2024-11-09T16:12:57.185335Z","shell.execute_reply":"2024-11-09T16:12:57.184255Z","shell.execute_reply.started":"2024-11-09T16:12:57.145331Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:57.187613Z","iopub.status.busy":"2024-11-09T16:12:57.186948Z","iopub.status.idle":"2024-11-09T16:12:59.457387Z","shell.execute_reply":"2024-11-09T16:12:59.456432Z","shell.execute_reply.started":"2024-11-09T16:12:57.187576Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([7207341, 79])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["train_X = torch.tensor(train_X,dtype = torch.float32).to(device)\n","\n","\n","train_y = torch.tensor(train_y, dtype = torch.float32).to(device)\n","val_X = torch.tensor(val_X,dtype = torch.float32).to(device)\n","\n","val_y = torch.tensor(val_y,dtype = torch.float32).to(device)\n","test_X = torch.tensor(test_X,dtype = torch.float32).to(device)\n","\n","test_y = torch.tensor(test_y,dtype = torch.float32).to(device)\n","train_weights = torch.tensor(train_weights, dtype=torch.float32).to(device)\n","val_weights = torch.tensor(val_weights, dtype=torch.float32).to(device)\n","test_weights = torch.tensor(test_weights, dtype=torch.float32).to(device)\n","train_X.shape"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.459374Z","iopub.status.busy":"2024-11-09T16:12:59.458975Z","iopub.status.idle":"2024-11-09T16:12:59.465348Z","shell.execute_reply":"2024-11-09T16:12:59.464344Z","shell.execute_reply.started":"2024-11-09T16:12:59.459331Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","def print_model_size(model):\n","    \"\"\"Prints the size of a PyTorch model in memory.\"\"\"\n","    param_size = 0\n","    for param in model.parameters():\n","        param_size += param.nelement() * param.element_size()\n","    buffer_size = 0\n","    for buffer in model.buffers():\n","        buffer_size += buffer.nelement() * buffer.element_size()\n","    size_all_mb = (param_size + buffer_size) / 1024**2\n","    print('Model size: {:.3f} MB'.format(size_all_mb))\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.467293Z","iopub.status.busy":"2024-11-09T16:12:59.466917Z","iopub.status.idle":"2024-11-09T16:12:59.476473Z","shell.execute_reply":"2024-11-09T16:12:59.475614Z","shell.execute_reply.started":"2024-11-09T16:12:59.467251Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","train_dataset = TensorDataset(train_X, train_y, train_weights)\n","val_dataset = TensorDataset(val_X, val_y, val_weights)\n","test_dataset = TensorDataset(test_X, test_y, test_weights)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.480363Z","iopub.status.busy":"2024-11-09T16:12:59.479796Z","iopub.status.idle":"2024-11-09T16:12:59.486832Z","shell.execute_reply":"2024-11-09T16:12:59.485931Z","shell.execute_reply.started":"2024-11-09T16:12:59.480325Z"},"trusted":true},"outputs":[],"source":["batch_size = 4096*2\n","train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size = batch_size,shuffle=False)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.488151Z","iopub.status.busy":"2024-11-09T16:12:59.487848Z","iopub.status.idle":"2024-11-09T16:12:59.495809Z","shell.execute_reply":"2024-11-09T16:12:59.495014Z","shell.execute_reply.started":"2024-11-09T16:12:59.488116Z"},"trusted":true},"outputs":[],"source":["# run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Local')\n","run_type = 'Transformer'"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.497269Z","iopub.status.busy":"2024-11-09T16:12:59.496952Z","iopub.status.idle":"2024-11-09T16:12:59.596920Z","shell.execute_reply":"2024-11-09T16:12:59.596030Z","shell.execute_reply.started":"2024-11-09T16:12:59.497229Z"},"trusted":true},"outputs":[],"source":["model = LSTM(input_size=79, hidden_dim=512, output_size = 1, num_layers = 1).to(device)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.598748Z","iopub.status.busy":"2024-11-09T16:12:59.598399Z","iopub.status.idle":"2024-11-09T16:12:59.604716Z","shell.execute_reply":"2024-11-09T16:12:59.603610Z","shell.execute_reply.started":"2024-11-09T16:12:59.598711Z"},"trusted":true},"outputs":[],"source":["# weighted r2 gotten from https://www.kaggle.com/code/chumajin/janestreet-updated-simulator-for-time-series-api\n","def r2_score(y_true, y_pred, weights):\n","    \"\"\"\n","    Calculate the sample weighted zero-mean R-squared score.\n","\n","    Parameters:\n","    y_true (numpy.ndarray): Ground-truth values for responder_6.\n","    y_pred (numpy.ndarray): Predicted values for responder_6.\n","    weights (numpy.ndarray): Sample weight vector.\n","\n","    Returns:\n","    float: The weighted zero-mean R-squared score.\n","    \"\"\"\n","    numerator = np.sum(weights * (y_true - y_pred)**2)\n","    denominator = np.sum(weights * y_true**2)\n","\n","    r2_score = 1 - numerator / denominator\n","    return r2_score"]},{"cell_type":"markdown","metadata":{},"source":["# Training Loop"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.606283Z","iopub.status.busy":"2024-11-09T16:12:59.605957Z","iopub.status.idle":"2024-11-09T16:12:59.617048Z","shell.execute_reply":"2024-11-09T16:12:59.616253Z","shell.execute_reply.started":"2024-11-09T16:12:59.606247Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","import time\n","from tqdm import tqdm\n","\n","def train_model(model, loader, optimizer, loss_function, device):\n","    model.train()\n","    total_loss = 0\n","    all_probs = []\n","    all_targets = []\n","    all_weights = []\n","\n","    pbar = tqdm(loader, desc='Training')\n","    start_time = time.time()\n","\n","    for batch_idx, (X_batch, y_batch, weights_batch) in enumerate(pbar):        \n","        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","        weights_batch = weights_batch.to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = model(X_batch)\n","\n","        loss_per_sample = loss_function(outputs, y_batch)\n","\n","        weighted_loss = loss_per_sample * weights_batch\n","        loss = weighted_loss.mean()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","\n","        all_probs.append(outputs.detach().cpu())\n","        all_targets.append(y_batch.cpu())\n","        all_weights.append(weights_batch.cpu())\n","\n","        if batch_idx > 0:\n","            time_per_batch = (time.time() - start_time) / batch_idx\n","            remaining_batches = len(loader) - batch_idx\n","            eta = remaining_batches * time_per_batch\n","            pbar.set_postfix({'loss': f'{loss.item():.4f}', \n","                            'ETA': f'{eta/60:.1f}min'})\n","            \n","\n","    all_probs = torch.cat(all_probs).numpy()\n","    all_targets = torch.cat(all_targets).numpy()\n","    all_weights = torch.cat(all_weights).numpy()\n","    mse = mean_squared_error(all_targets, all_probs,sample_weight = all_weights)\n","    r2 = r2_score(all_targets, all_probs,all_weights)  # average parameter depends on your task\n","\n","    avg_loss = total_loss / len(loader)\n","    return avg_loss, mse, r2"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.618695Z","iopub.status.busy":"2024-11-09T16:12:59.618342Z","iopub.status.idle":"2024-11-09T16:12:59.626515Z","shell.execute_reply":"2024-11-09T16:12:59.625596Z","shell.execute_reply.started":"2024-11-09T16:12:59.618654Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(model, loader):\n","    model.eval()\n","    all_probs = []\n","    all_targets = []\n","    all_weights = []\n","    with torch.no_grad():\n","        for X_batch, y_batch, weights_batch  in loader:\n","            outputs = model(X_batch)\n","            all_probs.append(outputs.cpu())\n","            all_targets.append(y_batch.cpu())\n","            all_weights.append(weights_batch.cpu())\n","    all_probs = torch.cat(all_probs).numpy()\n","    all_targets = torch.cat(all_targets).numpy()\n","    all_weights = torch.cat(all_weights).numpy()\n","    mse = mean_squared_error(all_targets, all_probs,sample_weight = all_weights)\n","    r2 = r2_score(all_targets, all_probs,all_weights)\n","\n","    return mse, r2\n"]},{"cell_type":"markdown","metadata":{},"source":["## Very Basic Training on 20 epochs, with early stopping over 10"]},{"cell_type":"markdown","metadata":{},"source":["Im using very few epochs due to the overfitting, plus the dataset is large enough more epochs seem to be detremintal with this type of model. The learning rate is set to .001, I am also using a weighted MSE Loss"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:12:59.628453Z","iopub.status.busy":"2024-11-09T16:12:59.627646Z","iopub.status.idle":"2024-11-09T16:12:59.639129Z","shell.execute_reply":"2024-11-09T16:12:59.638231Z","shell.execute_reply.started":"2024-11-09T16:12:59.628410Z"},"trusted":true},"outputs":[],"source":["if run_type == 'LSTM':\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","    loss_function = nn.MSELoss(reduction='none')\n","    epochs = 20\n","    best = float('-inf')\n","    degraded = 0\n","    best_model = model\n","    for epoch in range(epochs):\n","        train_loss, train_mse, train_r2 = train_model(model, train_loader, optimizer, loss_function, device)\n","        val_mse,val_r2 = evaluate_model(model, val_loader)\n","        print(f'epoch {epoch } train loss {train_loss:.4f}, train_r2 {train_r2:.4f}, train_mse {train_mse:.4f},val_mse {val_mse:.4f}, val_r2 { val_r2:.4f}')\n","        if val_r2 > best:\n","            best = val_r2\n","            best_model = copy.deepcopy(model)\n","            # torch.save(best_model.state_dict(), 'torchlstm.pth')\n","            degraded = 0\n","        else:\n","            degraded += 1\n","        if degraded > 10:\n","            break\n","    model = best_model\n","\n","    test_mse, test_r2 = evaluate_model(model, test_loader)\n","    print(f'test R2 score is {test_r2}')"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["class TransformerModel(nn.Module):\n","    def __init__(self, input_size, d_model=512, nhead=8, num_layers=3, dropout=0.1):\n","        super(TransformerModel, self).__init__()\n","        \n","        # 特征维度映射到transformer维度\n","        self.input_projection = nn.Linear(input_size, d_model)\n","        \n","        # 位置编码\n","        self.pos_encoder = nn.Sequential(\n","            GaussianNoise(std=0.1),\n","            nn.Dropout(dropout)\n","        )\n","        \n","        # Transformer编码器层\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            dim_feedforward=d_model*4,\n","            dropout=dropout,\n","            batch_first=True\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(\n","            encoder_layer,\n","            num_layers=num_layers\n","        )\n","        \n","        # 输出层\n","        self.output_layer = nn.Linear(d_model, 1)\n","        \n","    def forward(self, x):\n","        # 输入形状: [batch_size, features]\n","        # 添加序列维度\n","        x = x.unsqueeze(1)  # [batch_size, 1, features]\n","        \n","        # 投影到transformer维度\n","        x = self.input_projection(x)  # [batch_size, 1, d_model]\n","        \n","        # 添加位置编码和噪声\n","        x = self.pos_encoder(x)\n","        \n","        # Transformer编码\n","        x = self.transformer_encoder(x)\n","        \n","        # 取最后一个时间步的输出\n","        x = self.output_layer(x[:, -1, :])\n","        \n","        return x.squeeze()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 140\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 12\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]}],"source":["import wandb\n","wandb.init(project=\"your_project_name\")"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model size: 36.234 MB\n"]},{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/880 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 880/880 [03:11<00:00,  4.59it/s, loss=0.5467, ETA=0.0min] \n"]},{"name":"stdout","output_type":"stream","text":["epoch 0:\n","train loss 1.6426, train_r2 -0.0345, train_mse 0.6319\n","val_mse 0.6146, val_r2 0.0031\n","lr: 0.000099\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 880/880 [03:11<00:00,  4.60it/s, loss=0.5446, ETA=0.0min] \n"]},{"name":"stdout","output_type":"stream","text":["epoch 1:\n","train loss 1.5864, train_r2 0.0010, train_mse 0.6103\n","val_mse 0.6128, val_r2 0.0060\n","lr: 0.000098\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 880/880 [03:12<00:00,  4.56it/s, loss=0.5466, ETA=0.0min] \n"]},{"name":"stdout","output_type":"stream","text":["epoch 2:\n","train loss 1.5813, train_r2 0.0042, train_mse 0.6083\n","val_mse 0.6127, val_r2 0.0063\n","lr: 0.000095\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 880/880 [03:11<00:00,  4.61it/s, loss=0.5469, ETA=0.0min] \n"]},{"name":"stdout","output_type":"stream","text":["epoch 3:\n","train loss 1.5809, train_r2 0.0044, train_mse 0.6082\n","val_mse 0.6149, val_r2 0.0027\n","lr: 0.000090\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 880/880 [03:12<00:00,  4.58it/s, loss=0.5483, ETA=0.0min] \n"]},{"name":"stdout","output_type":"stream","text":["epoch 4:\n","train loss 1.5823, train_r2 0.0035, train_mse 0.6087\n","val_mse 0.6136, val_r2 0.0048\n","lr: 0.000085\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 880/880 [03:11<00:00,  4.60it/s, loss=0.5496, ETA=0.0min] \n"]},{"name":"stdout","output_type":"stream","text":["epoch 5:\n","train loss 1.5764, train_r2 0.0072, train_mse 0.6065\n","val_mse 0.6131, val_r2 0.0056\n","lr: 0.000079\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 880/880 [03:14<00:00,  4.51it/s, loss=0.5478, ETA=0.0min] \n"]},{"name":"stdout","output_type":"stream","text":["epoch 6:\n","train loss 1.5724, train_r2 0.0098, train_mse 0.6049\n","val_mse 0.6131, val_r2 0.0056\n","lr: 0.000073\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|█████████▉| 879/880 [03:16<00:00,  4.68it/s, loss=0.6200, ETA=0.0min] "]}],"source":["# 模型参数\n","input_size = 79  # 特征数量\n","d_model = 512    # Transformer的隐藏维度\n","nhead = 8        # 注意力头数\n","num_layers = 3   # Transformer层数\n","dropout = 0.1    # dropout率\n","\n","# 初始化模型\n","model = TransformerModel(\n","    input_size=input_size,\n","    d_model=d_model,\n","    nhead=nhead,\n","    num_layers=num_layers,\n","    dropout=dropout\n",").to(device)\n","\n","# 打印模型大小\n","print_model_size(model)\n","\n","# 优化器和学习率设置\n","optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n","loss_function = nn.MSELoss(reduction='none')\n","\n","# 训练循环\n","if run_type == 'Transformer':\n","    epochs = 20\n","    best = float('-inf')\n","    degraded = 0\n","    best_model = model\n","    \n","    for epoch in range(epochs):\n","        # 训练阶段\n","        train_loss, train_mse, train_r2 = train_model(\n","            model, train_loader, optimizer, loss_function, device\n","        )\n","        \n","        # 学习率调整\n","        scheduler.step()\n","        \n","        # 验证阶段\n","        val_mse, val_r2 = evaluate_model(model, val_loader)\n","        wandb.log({\n","            \"train_loss\": train_loss,\n","            \"train_r2\": train_r2,\n","            \"val_r2\": val_r2,\n","            \"learning_rate\": scheduler.get_last_lr()[0]\n","        })\n","        print(f'epoch {epoch}:')\n","        print(f'train loss {train_loss:.4f}, train_r2 {train_r2:.4f}, '\n","              f'train_mse {train_mse:.4f}')\n","        print(f'val_mse {val_mse:.4f}, val_r2 {val_r2:.4f}')\n","        print(f'lr: {scheduler.get_last_lr()[0]:.6f}')\n","        \n","        # 早停和模型保存\n","        if val_r2 > best:\n","            best = val_r2\n","            best_model = copy.deepcopy(model)\n","            torch.save(best_model.state_dict(), './model/js_transformer.pth')\n","            degraded = 0\n","        else:\n","            degraded += 1\n","            \n","        if degraded > 10:\n","            print(\"Early stopping triggered\")\n","            break\n","            \n","        # 清理GPU缓存\n","        torch.cuda.empty_cache()\n","    \n","    model = best_model\n","    \n","    # 测试集评估\n","    test_mse, test_r2 = evaluate_model(model, test_loader)\n","    print(f'test R2 score is {test_r2}')"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:16:45.039508Z","iopub.status.busy":"2024-11-09T16:16:45.038595Z","iopub.status.idle":"2024-11-09T16:16:45.057962Z","shell.execute_reply":"2024-11-09T16:16:45.056892Z","shell.execute_reply.started":"2024-11-09T16:16:45.039464Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), '/root/js_competitions/model/js_lstm.pth')"]},{"cell_type":"markdown","metadata":{},"source":["To use this notebook for a submission, train the model download it and upload it, replace your path to load the state dict with your uploaded input."]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:16:54.874716Z","iopub.status.busy":"2024-11-09T16:16:54.874304Z","iopub.status.idle":"2024-11-09T16:16:54.885926Z","shell.execute_reply":"2024-11-09T16:16:54.884889Z","shell.execute_reply.started":"2024-11-09T16:16:54.874678Z"},"trusted":true},"outputs":[],"source":["def predict_lstm(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n","    \"\"\"Make a prediction.\"\"\"\n","    global model\n","    global device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # Load the model if it's not already loaded\n","   \n","    model.load_state_dict(torch.load('/root/js_competitions/model/js_lstm.pth', map_location=device,weights_only= True))\n","    model.eval()  # Set the model to evaluation mode\n","    sel_cols  = [f\"feature_{i:02d}\" for i in range(79)]\n","\n","    # Process the test data using Polars\n","    # Select the same features used during training\n","\n","\n","    # Ensure all required columns are present\n","    missing_cols = set(sel_cols) - set(test.columns)\n","    if missing_cols:\n","        raise ValueError(f\"Missing columns in test data: {missing_cols}\")\n","\n","    # Select the features\n","    test_features = test.select(sel_cols)\n","\n","    # **Apply forward fill and then fill remaining missing values with zero**\n","    test_features = test_features.fill_null(strategy='forward').fill_null(0)\n","    test_features = normalize_dataframe(test_features,means,stds)\n","\n","    # Convert Polars DataFrame to NumPy array\n","    X_test = test_features.to_numpy()\n","\n","    # Convert to Torch tensor\n","    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n","\n","    # Make predictions\n","    with torch.no_grad():\n","        \n","        outputs = model(X_test_tensor)\n","        # Assuming the model outputs a tensor of shape (batch_size, 1)\n","        predictions = outputs.squeeze().cpu().numpy()\n","\n","    # Prepare the predictions DataFrame\n","    predictions_df = pl.DataFrame({\n","        'row_id': test['row_id'],\n","        'responder_6': predictions\n","    })\n","\n","    # The predict function must return a DataFrame\n","    assert isinstance(predictions_df, (pl.DataFrame, pd.DataFrame))\n","    # with columns 'row_id', 'responder_6'\n","    assert predictions_df.columns == ['row_id', 'responder_6']\n","    # and as many rows as the test data.\n","    assert len(predictions_df) == len(test)\n","\n","    return predictions_df"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def predict_transformer(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n","    \"\"\"Make a prediction.\"\"\"\n","    global model\n","    global device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    \n","    # 加载模型\n","    model.load_state_dict(torch.load(\n","        '/kaggle/working/transformer.pth',\n","        map_location=device,\n","        weights_only=True\n","    ))\n","    model.eval()\n","    \n","    sel_cols = [f\"feature_{i:02d}\" for i in range(79)]\n","    \n","    # 处理测试数据\n","    test_features = test.select(sel_cols)\n","    test_features = test_features.fill_null(strategy='forward').fill_null(0)\n","    test_features = normalize_dataframe(test_features, means, stds)\n","    \n","    # 转换为tensor\n","    X_test = test_features.to_numpy()\n","    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n","    \n","    # 预测\n","    with torch.no_grad():\n","        predictions = model(X_test_tensor).cpu().numpy()\n","    \n","    # 创建预测DataFrame\n","    predictions_df = pl.DataFrame({\n","        'row_id': test['row_id'],\n","        'responder_6': predictions\n","    })\n","    \n","    return predictions_df"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-11-09T16:17:12.876473Z","iopub.status.busy":"2024-11-09T16:17:12.876075Z","iopub.status.idle":"2024-11-09T16:17:12.921242Z","shell.execute_reply":"2024-11-09T16:17:12.920245Z","shell.execute_reply.started":"2024-11-09T16:17:12.876440Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'kaggle_evaluation'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkaggle_evaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjane_street_inference_server\u001b[39;00m\n\u001b[1;32m      9\u001b[0m inference_server \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     10\u001b[0m kaggle_evaluation\u001b[38;5;241m.\u001b[39mjane_street_inference_server\u001b[38;5;241m.\u001b[39mJSInferenceServer(predict_lstm)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAGGLE_IS_COMPETITION_RERUN\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_evaluation'"]}],"source":["import os\n","\n","import pandas as pd\n","import polars as pl\n","\n","import kaggle_evaluation.jane_street_inference_server\n","\n","\n","inference_server = \\\n","kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict_lstm)\n","\n","if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n","    inference_server.serve()\n","else:\n","    inference_server.run_local_gateway(\n","        (\n","            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n","            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n","        )\n","    )\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'transformers'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesTransformerModel, TimeSeriesTransformerConfig\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, TrainingArguments\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"]}],"source":["from transformers import TimeSeriesTransformerModel, TimeSeriesTransformerConfig\n","from transformers import Trainer, TrainingArguments\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9871156,"sourceId":84493,"sourceType":"competition"},{"sourceId":203644946,"sourceType":"kernelVersion"},{"modelId":148289,"modelInstanceId":125307,"sourceId":147672,"sourceType":"modelInstanceVersion"},{"modelId":148289,"modelInstanceId":125330,"sourceId":147696,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":4}
