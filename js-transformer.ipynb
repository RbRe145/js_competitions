{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoruilee/js_competitions/blob/kaggle-upload-1/js-transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PDbN_7P4JYXa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import os\n",
        "import statistics as stat\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./drive/MyDrive/Timer_checkpoints"
      ],
      "metadata": {
        "id": "DIHrGmAT5X0k",
        "outputId": "52f5c2ac-eba0-4c2f-e8f4-eaf03df59b7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer_anomaly_detection_1.0.ckpt  Timer_forecast_1.0.ckpt  Timer_imputation_1.0.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk4yq6QR2Jpu",
        "outputId": "fba0067e-b7b0-47fc-b533-d5685cc8387a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "XSjiKt2aCJPL",
        "outputId": "4e3ec84c-ffcb-47fb-92b9-9e9fb3a1a43b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change directory to a specific path\n",
        "os.chdir('/content/drive/MyDrive/checkpoints_kaggle_js')\n",
        "\n",
        "# Verify the current working directory\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "PGav8IhsCea8",
        "outputId": "6bd2a3a8-a31d-43a8-e5e3-427a0ffcab00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/checkpoints_kaggle_js\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thuml/Large-Time-Series-Model.git\n"
      ],
      "metadata": {
        "id": "zyfeJhqNCiWp",
        "outputId": "25bc190b-6beb-41f6-e4fd-a42897ff7060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Large-Time-Series-Model'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 292 (delta 105), reused 124 (delta 52), pack-reused 84 (from 1)\u001b[K\n",
            "Receiving objects: 100% (292/292), 17.49 MiB | 24.37 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "hdIzoZv_DMNQ",
        "outputId": "cc1b15d1-104f-49f6-f820-79e74243d075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jane-street-real-time-market-data-forecasting  len_5_d_model_64_nhead_32_num_layers_8_dropout_02\n",
            "Large-Time-Series-Model\t\t\t       Timer_forecast_1.0.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gxmPgsuaIVlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import polars as pl\n",
        "\n",
        "# Add the Timer repository to the Python path\n",
        "import sys\n",
        "sys.path.append('./Large-Time-Series-Model')  # Adjust the path if needed\n",
        "\n",
        "from models.Timer import Model  # Timer model\n",
        "\n",
        "# Use CPU for debugging (switch to GPU after resolving issues)\n",
        "device = torch.device(\"cpu\")  # Use CPU for clear error messages\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. Load Data\n",
        "# ==========================================\n",
        "valid_from = 0\n",
        "\n",
        "# Load data\n",
        "start_time = time.time()\n",
        "print(\"Loading data...\")\n",
        "jane_street_real_time_market_data_forecasting_path = \"./jane-street-real-time-market-data-forecasting\"  # Adjust path as needed\n",
        "alltraindata = pl.scan_parquet(f\"{jane_street_real_time_market_data_forecasting_path}/train.parquet\")\n",
        "train = alltraindata.filter(pl.col(\"date_id\") >= valid_from).collect()\n",
        "print(f\"Data loaded in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Prepare features\n",
        "start_time = time.time()\n",
        "print(\"Preparing features...\")\n",
        "feature_names = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "train_features = train.select(feature_names)\n",
        "train_features = train_features.fill_null(strategy='forward').fill_null(0)\n",
        "print(f\"Features prepared in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Prepare target data\n",
        "start_time = time.time()\n",
        "print(\"Preparing data...\")\n",
        "X = train_features.to_numpy()\n",
        "y = train.select([col for col in train.columns if col.startswith('responder_')]).to_numpy()  # Use all responder columns\n",
        "print(f\"Data prepared in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. Define Dataset and DataLoader\n",
        "# ==========================================\n",
        "seq_len = 96  # Match the patch_len of the pre-trained model\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y, seq_len):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X_seq = self.X[idx:idx + self.seq_len]\n",
        "        y_seq = self.y[idx + self.seq_len - 1]  # 目标值是序列末尾的 responders\n",
        "        return torch.tensor(X_seq, dtype=torch.float32), torch.tensor(y_seq, dtype=torch.float32)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Create train dataset and loader\n",
        "train_dataset = TimeSeriesDataset(X, y, seq_len=seq_len)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. Define Timer Model with Configs\n",
        "# ==========================================\n",
        "class Configs:\n",
        "    def __init__(self):\n",
        "        self.task_name = \"forecast\"  # Task type\n",
        "        self.ckpt_path = \"./Timer_forecast_1.0.ckpt\"  # Path to pre-trained checkpoint\n",
        "        self.patch_len = 96  # Match the patch_len in the pre-trained model\n",
        "        self.d_model = 1024  # Hidden dimension\n",
        "        self.d_ff = 2048  # Feedforward network dimension\n",
        "        self.e_layers = 8  # Number of Transformer encoder layers\n",
        "        self.n_heads = 8  # Number of attention heads\n",
        "        self.dropout = 0.1  # Dropout rate\n",
        "        self.output_attention = False  # Output attention or not\n",
        "        self.factor = 3  # Scaling factor for attention\n",
        "        self.activation = 'gelu'  # Add activation function, e.g., 'gelu'\n",
        "\n",
        "configs = Configs()\n",
        "\n",
        "# Initialize the Timer model\n",
        "model = Model(configs).to(device)\n",
        "print(\"Timer model initialized.\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. Simplified Weighted Loss Function for Debugging\n",
        "# ==========================================\n",
        "def weighted_loss(outputs, targets):\n",
        "    # print(\"Inside weighted_loss\")  # 调试信息\n",
        "\n",
        "    # 输出调试信息\n",
        "    # print(f\"Outputs shape: {outputs.shape}\")  # 模型的预测输出\n",
        "    # print(f\"Targets shape: {targets.shape}\")  # 目标值\n",
        "\n",
        "    # 提取最后一个时间步的预测结果\n",
        "    outputs = outputs[:, -1, :]  # 只取最后一个时间步\n",
        "    # print(f\"Outputs shape after slicing: {outputs.shape}\")\n",
        "\n",
        "    # 切片对齐\n",
        "    if outputs.shape[-1] != targets.shape[-1]:\n",
        "        outputs = outputs[:, :targets.shape[-1]]  # 对齐形状\n",
        "        # print(f\"Outputs shape after alignment: {outputs.shape}\")\n",
        "\n",
        "    # 计算损失\n",
        "    loss = F.mse_loss(outputs, targets)\n",
        "\n",
        "    # 为 `responder_6` 设置更高的权重\n",
        "    if targets.shape[-1] > 6:\n",
        "        weights = torch.ones_like(targets).to(device)\n",
        "        weights[:, 6] = 20.0\n",
        "        weighted_loss = loss * weights\n",
        "    else:\n",
        "        weighted_loss = loss\n",
        "\n",
        "    return weighted_loss.mean()\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 5. Debugging Training Loop\n",
        "# ==========================================\n",
        "# 训练循环\n",
        "# 检查 GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 初始化模型\n",
        "model = Model(configs).to(device)\n",
        "print(\"Timer model initialized.\")\n",
        "\n",
        "# 训练循环\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, loss, checkpoint_dir):\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "\n",
        "epochs = 1000  # 训练 1000 个 epoch\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch_idx, (batch_X, batch_y) in enumerate(train_loader):\n",
        "        # 将数据转移到 GPU\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        # 输出调试信息\n",
        "        print(f\"Batch index: {batch_idx}\")\n",
        "        print(f\"Batch_X shape: {batch_X.shape}\")\n",
        "        print(f\"Batch_y shape: {batch_y.shape}\")\n",
        "\n",
        "        # 清零梯度\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 模型前向传播\n",
        "        outputs = model(batch_X, None, None, None)\n",
        "        print(f\"Outputs shape: {outputs.shape}\")\n",
        "\n",
        "        # 检查输出和目标的数值范围\n",
        "        print(f\"Batch_y min: {batch_y.min().item()}, max: {batch_y.max().item()}\")\n",
        "        if torch.isnan(batch_y).any():\n",
        "            print(\"Error: batch_y contains NaN values!\")\n",
        "\n",
        "        # 计算损失\n",
        "        try:\n",
        "            loss = weighted_loss(outputs, batch_y)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in weighted_loss: {e}\")\n",
        "            break\n",
        "\n",
        "        # Debugging before backward\n",
        "        print(f\"Loss before backward: {loss.item()}\")\n",
        "\n",
        "        # 反向传播和优化\n",
        "        try:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        except Exception as e:\n",
        "            print(f\"Error during backward or step: {e}\")\n",
        "            break\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Debugging: 打印前几个 batch 的信息\n",
        "        if batch_idx >= 2:\n",
        "            break\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      # Save checkpoint at the end of each epoch\n",
        "      save_checkpoint(epoch + 1, model, optimizer, total_loss / len(train_loader), './')\n",
        "      print(f\"SAVED!!! Epoch [{epoch + 1}/{epochs}], Average Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # 打印 GPU 使用情况\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e6:.2f} MB\")\n",
        "        print(f\"GPU Memory Cached: {torch.cuda.memory_reserved() / 1e6:.2f} MB\")\n",
        "\n",
        "torch.save(model.state_dict(), \"./fine_tuned_timer_model.pth\")\n",
        "print(\"Fine-tuned Timer model saved successfully.\")\n"
      ],
      "metadata": {
        "id": "b2jYlUg1C58m",
        "outputId": "4e2b551f-0b2e-4947-d37a-c8da442c47fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Loading data...\n",
            "Data loaded in 28.50 seconds\n",
            "Preparing features...\n",
            "Features prepared in 4.31 seconds\n",
            "Preparing data...\n",
            "Data prepared in 2.13 seconds\n",
            "Train dataset size: 47127242\n",
            "loading model:  ./Timer_forecast_1.0.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/checkpoints_kaggle_js/./Large-Time-Series-Model/models/Timer.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sd = torch.load(self.ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timer model initialized.\n",
            "Using device: cuda\n",
            "loading model:  ./Timer_forecast_1.0.ckpt\n",
            "Timer model initialized.\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.7667107582092285\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -2.7249138355255127, max: 2.9662516117095947\n",
            "Loss before backward: 4.596888542175293\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.186418056488037\n",
            "Checkpoint saved at ./checkpoint_epoch_1.pth\n",
            "SAVED!!! Epoch [1/1000], Average Loss: 0.0000\n",
            "Epoch 1/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1131.19 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -4.964745998382568, max: 4.716275215148926\n",
            "Loss before backward: 5.479884147644043\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.822512149810791\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.478393077850342\n",
            "Epoch 2/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1126.28 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -2.1819584369659424, max: 4.193351745605469\n",
            "Loss before backward: 4.6447434425354\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 7.01412296295166\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.2962470054626465, max: 4.626258373260498\n",
            "Loss before backward: 6.498885631561279\n",
            "Epoch 3/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1123.76 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.81880521774292\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.179868698120117\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -2.5459415912628174, max: 3.0932533740997314\n",
            "Loss before backward: 4.251153945922852\n",
            "Epoch 4/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1128.94 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.0001397132873535\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.120381832122803\n",
            "Loss before backward: 5.819447994232178\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -4.490842342376709, max: 3.6363229751586914\n",
            "Loss before backward: 6.149953365325928\n",
            "Epoch 5/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1125.70 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 3.196226119995117\n",
            "Loss before backward: 4.998155117034912\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.654016971588135\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.3800554275512695\n",
            "Loss before backward: 5.855574131011963\n",
            "Epoch 6/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1128.94 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 3.7390832901000977\n",
            "Loss before backward: 6.392752647399902\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.0364649295806885, max: 4.579981327056885\n",
            "Loss before backward: 4.986818790435791\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -4.092906475067139, max: 5.0\n",
            "Loss before backward: 5.818170547485352\n",
            "Epoch 7/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1123.76 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 3.317086935043335\n",
            "Loss before backward: 5.381957054138184\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 4.606191158294678\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.287695407867432\n",
            "Epoch 8/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1126.99 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.533882141113281\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.739566326141357\n",
            "Loss before backward: 5.894423007965088\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -4.558722019195557, max: 5.0\n",
            "Loss before backward: 5.320084571838379\n",
            "Epoch 9/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1127.65 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.264678001403809\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.765617847442627, max: 3.2399957180023193\n",
            "Loss before backward: 4.474658966064453\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.595688819885254\n",
            "Loss before backward: 5.515496253967285\n",
            "Epoch 10/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1130.59 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -2.8182151317596436, max: 3.176879644393921\n",
            "Loss before backward: 4.988149642944336\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -2.9170215129852295, max: 3.38568377494812\n",
            "Loss before backward: 3.9863712787628174\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 7.201037883758545\n",
            "Epoch 11/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1129.20 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -2.7148194313049316, max: 4.991477966308594\n",
            "Loss before backward: 4.4431867599487305\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.2261993885040283, max: 3.287519931793213\n",
            "Loss before backward: 4.782853603363037\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.0464158058166504, max: 5.0\n",
            "Loss before backward: 4.5956268310546875\n",
            "Epoch 12/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1125.70 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.390289306640625\n",
            "Loss before backward: 5.806234836578369\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 3.8843350410461426\n",
            "Loss before backward: 5.979386329650879\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.39265775680542\n",
            "Epoch 13/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1128.94 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.674448490142822\n",
            "Loss before backward: 5.910295009613037\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.447902202606201\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 3.3032777309417725\n",
            "Loss before backward: 5.26353120803833\n",
            "Epoch 14/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1123.76 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.666422367095947\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.335274696350098\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.5006117820739746, max: 3.239367723464966\n",
            "Loss before backward: 5.446674823760986\n",
            "Epoch 15/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1128.94 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -4.687736988067627, max: 5.0\n",
            "Loss before backward: 5.4417853355407715\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.642427682876587, max: 5.0\n",
            "Loss before backward: 5.6123833656311035\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.68378210067749\n",
            "Loss before backward: 4.402493000030518\n",
            "Epoch 16/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1125.70 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.050041913986206, max: 5.0\n",
            "Loss before backward: 5.032536029815674\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.998905181884766\n",
            "Loss before backward: 4.939761161804199\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.584978103637695\n",
            "Epoch 17/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1128.94 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.828648805618286, max: 5.0\n",
            "Loss before backward: 4.142852306365967\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.078519582748413, max: 5.0\n",
            "Loss before backward: 4.6597137451171875\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -4.6713361740112305, max: 5.0\n",
            "Loss before backward: 6.048580169677734\n",
            "Epoch 18/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1123.76 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 6.268904685974121\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.583769798278809\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -4.203559875488281, max: 4.913488864898682\n",
            "Loss before backward: 5.080090045928955\n",
            "Epoch 19/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1127.00 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 5.0\n",
            "Loss before backward: 5.531745910644531\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.5037429332733154, max: 5.0\n",
            "Loss before backward: 5.425383567810059\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.0817031860351562, max: 5.0\n",
            "Loss before backward: 5.882737159729004\n",
            "Epoch 20/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1127.65 MB\n",
            "GPU Memory Cached: 3323.99 MB\n",
            "Batch index: 0\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -2.5837254524230957, max: 4.8771514892578125\n",
            "Loss before backward: 5.027098655700684\n",
            "Batch index: 1\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -5.0, max: 4.513487339019775\n",
            "Loss before backward: 5.346965789794922\n",
            "Batch index: 2\n",
            "Batch_X shape: torch.Size([64, 96, 79])\n",
            "Batch_y shape: torch.Size([64, 9])\n",
            "Outputs shape: torch.Size([64, 96, 79])\n",
            "Batch_y min: -3.78432297706604, max: 5.0\n",
            "Loss before backward: 4.893901824951172\n",
            "Epoch 21/1000, Loss: 0.0000\n",
            "GPU Memory Allocated: 1130.91 MB\n",
            "GPU Memory Cached: 3323.99 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# 3. Define Timer Model with Configs\n",
        "# ==========================================\n",
        "class Configs:\n",
        "    def __init__(self):\n",
        "        self.task_name = \"forecast\"  # Task type\n",
        "        self.ckpt_path = \"./Timer_forecast_1.0.ckpt\"  # Path to checkpoint\n",
        "        self.patch_len = 96  # Patch length\n",
        "        self.d_model = 1024  # Hidden dimension\n",
        "        self.d_ff = 2048  # Feedforward network dimension\n",
        "        self.e_layers = 8  # Number of Transformer encoder layers\n",
        "        self.n_heads = 8  # Number of attention heads\n",
        "        self.dropout = 0.1  # Dropout rate\n",
        "        self.output_attention = False  # Output attention or not\n",
        "        self.factor = 3  # Scaling factor for attention (set to 3 by default)\n",
        "        self.activation = 'gelu'  # Add activation function, e.g., 'gelu'\n",
        "\n",
        "\n",
        "configs = Configs()\n",
        "\n",
        "# Initialize the Timer model\n",
        "model = Model(configs).to(device)\n",
        "print(\"Timer model initialized.\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. Define Weighted Loss Function\n",
        "# ==========================================\n",
        "def weighted_loss(outputs, targets):\n",
        "    loss = F.mse_loss(outputs, targets, reduction='none')\n",
        "\n",
        "    # Find the index of 'responder_6' dynamically\n",
        "    responder_columns = [col for col in train.columns if col.startswith('responder_')]\n",
        "    responder_6_index = responder_columns.index('responder_6')\n",
        "\n",
        "    # Apply a higher weight for 'responder_6'\n",
        "    weights = torch.ones_like(targets).to(device)\n",
        "    weights[:, responder_6_index] = 20.0  # Assign higher weight to 'responder_6'\n",
        "\n",
        "    weighted_loss = loss * weights\n",
        "    return weighted_loss.mean()\n",
        "\n",
        "# ==========================================\n",
        "# 5. Fine-Tune the Model\n",
        "# ==========================================\n",
        "# Define optimizer and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10  # Number of epochs\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_X, None, None, None)  # Timer model expects additional inputs, pass None for unused\n",
        "\n",
        "        # Compute loss\n",
        "        loss = weighted_loss(outputs, batch_y)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. Save the Fine-Tuned Model\n",
        "# ==========================================\n",
        "torch.save(model.state_dict(), \"./fine_tuned_timer_model.pth\")\n",
        "print(\"Fine-tuned Timer model saved successfully.\")\n"
      ],
      "metadata": {
        "id": "PN3JXAtLFSav",
        "outputId": "74af439c-c59b-496c-f8c9-27a705887a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model:  ./Timer_forecast_1.0.ckpt\n",
            "Timer model initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-21edc1359b27>:29: UserWarning: Using a target size (torch.Size([64, 9])) that is different to the input size (torch.Size([64, 96, 79])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = F.mse_loss(outputs, targets, reduction='none')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (79) must match the size of tensor b (9) at non-singleton dimension 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-21edc1359b27>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-21edc1359b27>\u001b[0m in \u001b[0;36mweighted_loss\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# ==========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweighted_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Find the index of 'responder_6' dynamically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3789\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m     return torch._C._nn.mse_loss(\n\u001b[1;32m   3793\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (79) must match the size of tensor b (9) at non-singleton dimension 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlhO24Ud2Zre",
        "outputId": "2066f533-f7ef-4c68-e324-8ae994bbcbf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.csv\t   lags.parquet    sample_submission.csv  train.parquet\n",
            "kaggle_evaluation  responders.csv  test.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./drive/jane-street-real-time-market-data-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKrrMIJF2LaH",
        "outputId": "f1e43767-3996-4eab-a848-8b6a419ff35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './drive/jane-street-real-time-market-data-forecasting': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0eCLNsNZJYXc"
      },
      "outputs": [],
      "source": [
        "\n",
        "jane_street_real_time_market_data_forecasting_path = \"./drive/MyDrive/jane-street-real-time-market-data-forecasting\"  # Set your path here\n",
        "checkpoint_dir = \"./drive/MyDrive/checkpoints_kaggle_js/len_5_d_model_64_nhead_32_num_layers_8_dropout_02\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YFXUfE_iJYXd",
        "outputId": "f0291cd8-fdd6-4150-f0fb-c50e68bc4b01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded in 11.90 seconds\n",
            "Preparing features...\n",
            "Features prepared in 4.34 seconds\n",
            "Preparing data...\n",
            "Data prepared in 2.50 seconds\n",
            "Create dataset and data loader\n",
            "Dataset and DataLoader created in 0.00 seconds\n",
            "Set up device for multi-GPU environment\n",
            "Create model\n",
            "Model created in 0.02 seconds\n",
            "Move model to GPU\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import polars as pl\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "valid_from = 0\n",
        "\n",
        "# Load data\n",
        "start_time = time.time()\n",
        "print(\"Loading data...\")\n",
        "alltraindata = pl.scan_parquet(f\"{jane_street_real_time_market_data_forecasting_path}/train.parquet\")\n",
        "train = alltraindata.filter(pl.col(\"date_id\") >= valid_from).collect()\n",
        "print(f\"Data loaded in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Prepare features\n",
        "start_time = time.time()\n",
        "print(\"Preparing features...\")\n",
        "feature_names = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "train_features = train.select(feature_names)\n",
        "train_features = train_features.fill_null(strategy='forward').fill_null(0)\n",
        "print(f\"Features prepared in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Prepare data\n",
        "start_time = time.time()\n",
        "print(\"Preparing data...\")\n",
        "X = train_features.to_numpy()\n",
        "y = train.select([col for col in train.columns if col.startswith('responder_')]).to_numpy()  # Use all responder columns\n",
        "print(f\"Data prepared in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Define sequence length\n",
        "seq_len = 5\n",
        "\n",
        "\n",
        "# Custom weighted loss function to prioritize responder_6\n",
        "def weighted_loss(outputs, targets):\n",
        "    loss = F.mse_loss(outputs, targets, reduction='none')\n",
        "\n",
        "    # Find the index of 'responder_6' dynamically\n",
        "    responder_columns = [col for col in train.columns if col.startswith('responder_')]\n",
        "    responder_6_index = responder_columns.index('responder_6')\n",
        "\n",
        "    # Apply a higher weight for the 'responder_6' target column\n",
        "    weights = torch.ones_like(targets).to(device)  # Ensure weights are on GPU\n",
        "    responder_6_weight = 20.0  # Assign higher weight to responder_6\n",
        "    weights[:, responder_6_index] = responder_6_weight\n",
        "\n",
        "    weighted_loss = loss * weights\n",
        "    return weighted_loss.mean()\n",
        "\n",
        "\n",
        "# Custom Dataset Class for Lazy Sequence Generation\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y, seq_len):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sequence of features\n",
        "        X_seq = self.X[idx:idx + self.seq_len]\n",
        "        # Get the target for the end of the sequence\n",
        "        y_seq = self.y[idx + self.seq_len]\n",
        "        # Convert to tensor\n",
        "        X_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
        "        y_tensor = torch.tensor(y_seq, dtype=torch.float32)\n",
        "        return X_tensor, y_tensor\n",
        "\n",
        "# Create dataset and data loader\n",
        "print('Create dataset and data loader')\n",
        "dataset = TimeSeriesDataset(X, y, seq_len=seq_len)\n",
        "batch_size = 64\n",
        "start_time = time.time()\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "print(f\"Dataset and DataLoader created in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Set up device for multi-GPU environment\n",
        "print('Set up device for multi-GPU environment')\n",
        "if torch.cuda.is_available():\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
        "        device = torch.device(\"cuda\")  # Use all available GPUs\n",
        "    else:\n",
        "        device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Warning: CUDA is not available. Training will run on CPU.\")\n",
        "\n",
        "# Transformer Model Definition\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_size, d_model=64, nhead=32, num_layers=8, dropout=0.2, output_size=6):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_size, d_model)\n",
        "        self.pos_encoder = nn.Sequential(\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.output_layer = nn.Linear(d_model, output_size)  # Output matches number of responder columns\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.output_layer(x[:, -1, :])  # Use the output from the last time step\n",
        "        return x.squeeze()\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = X.shape[1]  # Number of features per time step\n",
        "output_size = y.shape[1]  # Number of responder columns\n",
        "print('Create model')\n",
        "start_time = time.time()\n",
        "model = TransformerModel(input_size=input_size, d_model=64, nhead=2, num_layers=2, dropout=0.2, output_size=output_size)\n",
        "print(f\"Model created in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "print('Move model to GPU')\n",
        "# Set up DataParallel to use multiple GPUs\n",
        "if torch.cuda.device_count() > 1:\n",
        "    model = nn.DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = torch.nn.MSELoss()  # Base loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('create_dir')\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "# Early Stopping Parameters\n",
        "early_stopping_patience = 10\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# Track Loss for Plotting\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop with gradient clipping and validation\n",
        "for epoch in range(epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    print(f\"Start Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    # Training Phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (batch_X, batch_y) in enumerate(data_loader):\n",
        "        batch_start_time = time.time()\n",
        "\n",
        "        # Move batch data to the appropriate device\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_X)\n",
        "\n",
        "        # Compute weighted loss\n",
        "        loss = weighted_loss(outputs, batch_y)\n",
        "\n",
        "        # Skip NaN losses\n",
        "        if torch.isnan(loss):\n",
        "            print(f\"Skipping batch {batch_idx} due to NaN loss\")\n",
        "            continue\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if batch_idx % 3000 == 0:\n",
        "            print(f\"Batch {batch_idx + 1} completed in {time.time() - batch_start_time:.2f} seconds, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss = running_loss / len(data_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_batch_X, val_batch_y in val_loader:  # Ensure val_loader is defined\n",
        "            val_batch_X, val_batch_y = val_batch_X.to(device), val_batch_y.to(device)\n",
        "            val_outputs = model(val_batch_X)\n",
        "            val_loss += weighted_loss(val_outputs, val_batch_y).item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] completed in {time.time() - epoch_start_time:.2f} seconds\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Update Scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), \"best_transformer_model.pth\")\n",
        "        print(\"Best model saved as best_transformer_model.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Save checkpoint after every epoch\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"transformer_checkpoint_epoch_{epoch+1}.pth\")\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f\"Checkpoint saved as {checkpoint_path}\")\n",
        "\n",
        "# Save the final trained model\n",
        "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
        "print(\"Model saved as transformer_model.pth\")\n",
        "\n",
        "# Plot Losses\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n",
        "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UN1QOPqB2Quy",
        "outputId": "df6ffb51-9e08-4146-fccd-db44acb8fe27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_dir\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'epochs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d13b4a015be8>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Training loop with gradient clipping and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Start Epoch {epoch+1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load checkpoint for the model\n",
        "checkpoint_path = \"checkpoints/transformer_checkpoint_epoch_14.pth\"\n",
        "model.load_state_dict(torch.load(checkpoint_path))\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "# Early Stopping Parameters\n",
        "early_stopping_patience = 10\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# Track Loss for Plotting\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop with gradient clipping and validation\n",
        "for epoch in range(15, epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    print(f\"Start Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    # Training Phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (batch_X, batch_y) in enumerate(data_loader):\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "        loss = weighted_loss(outputs, batch_y)\n",
        "\n",
        "        # Skip NaN losses\n",
        "        if torch.isnan(loss):\n",
        "            print(f\"Skipping batch {batch_idx} due to NaN loss\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if batch_idx % 3000 == 0:\n",
        "            print(f\"Batch {batch_idx + 1} completed, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss = running_loss / len(data_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_batch_X, val_batch_y in val_loader:  # Assuming val_loader is defined\n",
        "            val_batch_X, val_batch_y = val_batch_X.to(device), val_batch_y.to(device)\n",
        "            val_outputs = model(val_batch_X)\n",
        "            val_loss += weighted_loss(val_outputs, val_batch_y).item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] completed in {time.time() - epoch_start_time:.2f} seconds\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Update Scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # Save the best model\n",
        "        torch.save(model.state_dict(), \"best_transformer_model.pth\")\n",
        "        print(\"Best model saved as best_transformer_model.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Save checkpoint after each epoch\n",
        "    torch.save(model.state_dict(), f\"checkpoints/transformer_checkpoint_restart_epoch_{epoch+1}.pth\")\n",
        "    print(f\"Checkpoint saved as checkpoints/transformer_checkpoint_restart_epoch_{epoch+1}.pth\")\n",
        "\n",
        "# Plot Losses\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n",
        "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Lm5UuZZJzkCS",
        "outputId": "0f57b83b-ed52-406f-e264-862c453836cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-aefc53e62121>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'checkpoints/transformer_checkpoint_epoch_14.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-aefc53e62121>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load checkpoint for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"checkpoints/transformer_checkpoint_epoch_14.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints/transformer_checkpoint_epoch_14.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6sTLoR2JYXg"
      },
      "outputs": [],
      "source": [
        "if run_type == 'Transformer':\n",
        "    # 模型参数\n",
        "    input_size = 79\n",
        "    d_model = 512\n",
        "    nhead = 8\n",
        "    num_layers = 3\n",
        "    dropout = 0.1\n",
        "\n",
        "    # 初始化模型\n",
        "    model = TransformerModel(\n",
        "        input_size=input_size,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    print_model_size(model)\n",
        "\n",
        "    # 优化器设置\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
        "    loss_function = nn.MSELoss(reduction='none')\n",
        "\n",
        "    # 训练循环\n",
        "    epochs = 20\n",
        "    best = float('-inf')\n",
        "    degraded = 0\n",
        "    best_model = model\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_mse, train_r2 = train_model(\n",
        "            model, train_loader, optimizer, loss_function, device\n",
        "        )\n",
        "\n",
        "        scheduler.step()\n",
        "        val_mse, val_r2 = evaluate_model(model, val_loader)\n",
        "\n",
        "        print(f'epoch {epoch}:')\n",
        "        print(f'train loss {train_loss:.4f}, train_r2 {train_r2:.4f}, '\n",
        "              f'train_mse {train_mse:.4f}')\n",
        "        print(f'val_mse {val_mse:.4f}, val_r2 {val_r2:.4f}')\n",
        "        print(f'lr: {scheduler.get_last_lr()[0]:.6f}')\n",
        "\n",
        "        if val_r2 > best:\n",
        "            best = val_r2\n",
        "            best_model = copy.deepcopy(model)\n",
        "            torch.save(best_model.state_dict(), f'./model/js_{run_type}_unnorm.pth')\n",
        "            degraded = 0\n",
        "        else:\n",
        "            degraded += 1\n",
        "\n",
        "        if degraded > 10:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    model = best_model\n",
        "    test_mse, test_r2 = evaluate_model(model, test_loader)\n",
        "    print(f'test R2 score is {test_r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQyKZgiWJYXg"
      },
      "outputs": [],
      "source": [
        "lags_ : pl.DataFrame | None = None\n",
        "\n",
        "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
        "    \"\"\"Make predictions using either LSTM or Transformer model\"\"\"\n",
        "    global lags_\n",
        "    if lags is not None:\n",
        "        lags_ = lags\n",
        "\n",
        "    # 初始化预测DataFrame\n",
        "    predictions = test.select(\n",
        "        'row_id',\n",
        "        pl.lit(0.0).alias('responder_6'),\n",
        "    )\n",
        "\n",
        "    # 选择特征列\n",
        "    feature_cols = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "\n",
        "    # 处理测试数据\n",
        "    test_features = test.select(feature_cols)\n",
        "    test_features = test_features.fill_null(strategy='forward').fill_null(0)\n",
        "\n",
        "    # 转换为tensor\n",
        "    X_test = test_features.to_numpy()\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "\n",
        "    # 进行预测\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "    # 更新预测结果\n",
        "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
        "\n",
        "    # 验证输出格式\n",
        "    assert isinstance(predictions, (pl.DataFrame, pd.DataFrame))\n",
        "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
        "    assert len(predictions) == len(test)\n",
        "    print(predictions)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2v28mgbJYXg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "import kaggle_evaluation.jane_street_inference_server\n",
        "\n",
        "\n",
        "inference_server = kaggle_evaluation \\\n",
        "                        .jane_street_inference_server.JSInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    inference_server.run_local_gateway(\n",
        "        (\n",
        "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
        "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
        "        )\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}