{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoruilee/js_competitions/blob/kaggle-upload-1/js-transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PDbN_7P4JYXa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import os\n",
        "import statistics as stat\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "nk4yq6QR2Jpu",
        "outputId": "506d84ca-bcd3-4067-c7cb-4f25d540c655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/jane-street-real-time-market-data-forecasting"
      ],
      "metadata": {
        "id": "qlhO24Ud2Zre",
        "outputId": "2066f533-f7ef-4c68-e324-8ae994bbcbf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.csv\t   lags.parquet    sample_submission.csv  train.parquet\n",
            "kaggle_evaluation  responders.csv  test.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./drive/jane-street-real-time-market-data-forecasting"
      ],
      "metadata": {
        "id": "fKrrMIJF2LaH",
        "outputId": "f1e43767-3996-4eab-a848-8b6a419ff35a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './drive/jane-street-real-time-market-data-forecasting': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0eCLNsNZJYXc"
      },
      "outputs": [],
      "source": [
        "\n",
        "jane_street_real_time_market_data_forecasting_path = \"./drive/MyDrive/jane-street-real-time-market-data-forecasting\"  # Set your path here\n",
        "checkpoint_dir = \"./drive/MyDrive/kaggle_js_checkpoints_transformer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFXUfE_iJYXd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Load data using Parquet format\n",
        "jane_street_real_time_market_data_forecasting_path = \"./drive/MyDrive/jane-street-real-time-market-data-forecasting\"  # Set your path here\n",
        "\n",
        "valid_from = 100  # Example valid_from date threshold\n",
        "\n",
        "# Load data\n",
        "alltraindata = pl.scan_parquet(f\"{jane_street_real_time_market_data_forecasting_path}/train.parquet\")\n",
        "train = alltraindata.filter(pl.col(\"date_id\") >= valid_from).collect()\n",
        "\n",
        "# Prepare features\n",
        "feature_names = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "train_features = train.select(feature_names)\n",
        "train_features = train_features.fill_null(strategy='forward').fill_null(0)\n",
        "\n",
        "# Prepare data\n",
        "X = train_features.to_numpy()\n",
        "y = train.select([col for col in train.columns if col.startswith('responder_')]).to_numpy()  # Use all responder columns\n",
        "\n",
        "# Define sequence length\n",
        "seq_len = 10  # Number of time steps in each sequence\n",
        "\n",
        "# Create sequences\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "\n",
        "for i in range(len(X) - seq_len):\n",
        "    X_seq.append(X[i:i + seq_len])  # Create a sequence of length `seq_len`\n",
        "    y_seq.append(y[i + seq_len])  # Predict the next point after the sequence\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_seq = np.array(X_seq)  # Shape: (num_sequences, seq_len, input_size)\n",
        "y_seq = np.array(y_seq)  # Shape: (num_sequences, output_size)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_tensor = torch.tensor(X_seq, dtype=torch.float32).cuda()  # Move data to GPU\n",
        "y_tensor = torch.tensor(y_seq, dtype=torch.float32).cuda()  # Move data to GPU\n",
        "\n",
        "# Create DataLoader for batching\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "batch_size = 2\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Transformer Model Definition\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_size, d_model=128, nhead=4, num_layers=2, dropout=0.2, output_size=6):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_size, d_model)\n",
        "        self.pos_encoder = nn.Sequential(\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.output_layer = nn.Linear(d_model, output_size)  # Output matches number of responder columns\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.output_layer(x[:, -1, :])  # Use the output from the last time step\n",
        "        return x.squeeze()\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = X_seq.shape[2]  # Number of features per time step\n",
        "output_size = y_seq.shape[1]  # Number of responder columns\n",
        "model = TransformerModel(input_size=input_size, d_model=128, nhead=4, num_layers=2, dropout=0.2, output_size=output_size).cuda()  # Move model to GPU\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = torch.nn.MSELoss()  # Base loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Custom weighted loss function to prioritize responder_6\n",
        "def weighted_loss(outputs, targets):\n",
        "    loss = F.mse_loss(outputs, targets, reduction='none')\n",
        "\n",
        "    # Apply a higher weight for the rows corresponding to responder_6\n",
        "    weights = torch.ones_like(targets).cuda()  # Ensure weights are on GPU\n",
        "    responder_6_indices = (updated_responders_df['responder'] == 'responder_6').values.nonzero()[0]\n",
        "    for idx in responder_6_indices:\n",
        "        weights[idx, :] = 5.0  # Assign higher weight to responder_6\n",
        "\n",
        "    weighted_loss = loss * weights\n",
        "    return weighted_loss.mean()\n",
        "\n",
        "# Training loop\n",
        "checkpoint_dir = \"./drive/MyDrive/kaggle_js_checkpoints_transformer\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for batch_X, batch_y in data_loader:\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_X)\n",
        "\n",
        "        # Compute weighted loss\n",
        "        loss = weighted_loss(outputs, batch_y)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print loss for every epoch\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Save checkpoint after every epoch\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"transformer_checkpoint_epoch_{epoch+1}.pth\")\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f\"Checkpoint saved as {checkpoint_path}\")\n",
        "\n",
        "# Save the final trained model\n",
        "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
        "print(\"Model saved as transformer_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6sTLoR2JYXg"
      },
      "outputs": [],
      "source": [
        "if run_type == 'Transformer':\n",
        "    # 模型参数\n",
        "    input_size = 79\n",
        "    d_model = 512\n",
        "    nhead = 8\n",
        "    num_layers = 3\n",
        "    dropout = 0.1\n",
        "\n",
        "    # 初始化模型\n",
        "    model = TransformerModel(\n",
        "        input_size=input_size,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    print_model_size(model)\n",
        "\n",
        "    # 优化器设置\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
        "    loss_function = nn.MSELoss(reduction='none')\n",
        "\n",
        "    # 训练循环\n",
        "    epochs = 20\n",
        "    best = float('-inf')\n",
        "    degraded = 0\n",
        "    best_model = model\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_mse, train_r2 = train_model(\n",
        "            model, train_loader, optimizer, loss_function, device\n",
        "        )\n",
        "\n",
        "        scheduler.step()\n",
        "        val_mse, val_r2 = evaluate_model(model, val_loader)\n",
        "\n",
        "        print(f'epoch {epoch}:')\n",
        "        print(f'train loss {train_loss:.4f}, train_r2 {train_r2:.4f}, '\n",
        "              f'train_mse {train_mse:.4f}')\n",
        "        print(f'val_mse {val_mse:.4f}, val_r2 {val_r2:.4f}')\n",
        "        print(f'lr: {scheduler.get_last_lr()[0]:.6f}')\n",
        "\n",
        "        if val_r2 > best:\n",
        "            best = val_r2\n",
        "            best_model = copy.deepcopy(model)\n",
        "            torch.save(best_model.state_dict(), f'./model/js_{run_type}_unnorm.pth')\n",
        "            degraded = 0\n",
        "        else:\n",
        "            degraded += 1\n",
        "\n",
        "        if degraded > 10:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    model = best_model\n",
        "    test_mse, test_r2 = evaluate_model(model, test_loader)\n",
        "    print(f'test R2 score is {test_r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQyKZgiWJYXg"
      },
      "outputs": [],
      "source": [
        "lags_ : pl.DataFrame | None = None\n",
        "\n",
        "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
        "    \"\"\"Make predictions using either LSTM or Transformer model\"\"\"\n",
        "    global lags_\n",
        "    if lags is not None:\n",
        "        lags_ = lags\n",
        "\n",
        "    # 初始化预测DataFrame\n",
        "    predictions = test.select(\n",
        "        'row_id',\n",
        "        pl.lit(0.0).alias('responder_6'),\n",
        "    )\n",
        "\n",
        "    # 选择特征列\n",
        "    feature_cols = [f\"feature_{i:02d}\" for i in range(79)]\n",
        "\n",
        "    # 处理测试数据\n",
        "    test_features = test.select(feature_cols)\n",
        "    test_features = test_features.fill_null(strategy='forward').fill_null(0)\n",
        "\n",
        "    # 转换为tensor\n",
        "    X_test = test_features.to_numpy()\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "\n",
        "    # 进行预测\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(X_test_tensor).cpu().numpy()\n",
        "\n",
        "    # 更新预测结果\n",
        "    predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
        "\n",
        "    # 验证输出格式\n",
        "    assert isinstance(predictions, (pl.DataFrame, pd.DataFrame))\n",
        "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
        "    assert len(predictions) == len(test)\n",
        "    print(predictions)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2v28mgbJYXg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "import kaggle_evaluation.jane_street_inference_server\n",
        "\n",
        "\n",
        "inference_server = kaggle_evaluation \\\n",
        "                        .jane_street_inference_server.JSInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    inference_server.run_local_gateway(\n",
        "        (\n",
        "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
        "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
        "        )\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}